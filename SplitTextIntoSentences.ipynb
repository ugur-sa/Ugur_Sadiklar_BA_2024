{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n",
    "\n",
    "# NLTK's vordefinierte Abkürzungen laden\n",
    "punkt_param = PunktParameters()\n",
    "\n",
    "# Eigene Abkürzungen hinzufügen\n",
    "abbreviation_types = set(['no', 'dr', 'vs', 'mr', 'mrs', 'prof', 'inc', 'a.m', 'p.m', 'u.s', 'jan', 'feb', 'mar', 'apr', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec', 'sept', 'octo', 'novem', 'dece'])\n",
    "punkt_param.abbrev_types.update(abbreviation_types)\n",
    "\n",
    "# Benutzerdefinierten PunktSentenceTokenizer erstellen\n",
    "tokenizer = PunktSentenceTokenizer(punkt_param)\n",
    "\n",
    "def sentence_tokenize(text):\n",
    "    return tokenizer.tokenize(text)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    n = text.find(') -')\n",
    "    if n != -1:\n",
    "        text = text[n+4:]\n",
    "\n",
    "    # Regex-Muster, das Text in Klammern am Ende des Strings erfasst\n",
    "    pattern = r'\\s*\\([^)]*\\)\\s*$'\n",
    "\n",
    "    # Entferne den Text in Klammern am Ende des Strings\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Entferne alle Zeilenumbrüche\n",
    "    cleaned_text = cleaned_text.replace('\\n', ' ')\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('sentiment.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the sentence table if it doesn't exist\n",
    "# cursor.execute('''\n",
    "#     CREATE TABLE IF NOT EXISTS sentences (\n",
    "#         id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "#         text_id INTEGER,\n",
    "#         sentence_text TEXT,\n",
    "#         sequence INTEGER,\n",
    "#         finbert_result TEXT,\n",
    "#         dffnsa_result TEXT,\n",
    "#         fsa_result TEXT,\n",
    "#         final_sentiment TEXT,\n",
    "#         FOREIGN KEY (text_id) REFERENCES sentiment(id)\n",
    "#     )\n",
    "# ''')\n",
    "\n",
    "# Retrieve the texts from the sentiment table\n",
    "cursor.execute('SELECT id, text FROM sentiment WHERE id = 1400')\n",
    "texts = cursor.fetchall()\n",
    "\n",
    "# Iterate over each text\n",
    "for text_id, text in texts:\n",
    "    cleaned_text = clean_text(text)\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sentence_tokenize(cleaned_text)\n",
    "    \n",
    "    # Insert each sentence into the sentence table\n",
    "    for sequence, sentence in enumerate(sentences):\n",
    "        # cursor.execute('''\n",
    "        #     INSERT INTO sentences (text_id, sentence_text, sequence)\n",
    "        #     VALUES (?, ?, ?)\n",
    "        # ''', (text_id, sentence, sequence))\n",
    "         print(sentence + '\\n')\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "digits = \"([0-9])\"\n",
    "multiple_dots = r'\\.{2,}'\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('sentiment.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the sentence table if it doesn't exist\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS sentences (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        text_id INTEGER,\n",
    "        sentence_text TEXT,\n",
    "        sequence INTEGER,\n",
    "        finbert_result TEXT,\n",
    "        finbert_score REAL,\n",
    "        dffnsa_result TEXT,\n",
    "        dffnsa_score REAL,\n",
    "        fsa_result TEXT,\n",
    "        fsa_score REAL,\n",
    "        final_sentiment TEXT,\n",
    "        FOREIGN KEY (text_id) REFERENCES sentiment(id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('SELECT id, text FROM sentiment')\n",
    "text = cursor.fetchall()\n",
    "\n",
    "\n",
    "def remove_author_notes(text):\n",
    "    # Broaden pattern to match updates or other notes at the beginning\n",
    "    text = re.sub(r'^\\([^\\)]+\\)\\s*', '', text)\n",
    "\n",
    "    # Pattern to match author and location, updated to handle variations\n",
    "    text = re.sub(r'By\\s.+?\\s\\(.+?\\)\\s*[-–]\\s*', '', text)\n",
    "\n",
    "    # Pattern to match Month Day () -\n",
    "    text = re.sub(r'\\w{3}\\s\\d{1,2}\\s\\([^)]*\\)\\s*-\\s*', '', text)\n",
    "\n",
    "    # Pattern to match additional reporting or editing notes at the end, updated for flexibility\n",
    "    text = re.sub(r'\\(Reporting by [\\w\\s,]+;\\s*additional reporting by [\\w\\s,]+;\\s*Editing by [\\w\\s,]+\\)$', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text\n",
    "\n",
    "# https://stackoverflow.com/a/31505798 (source)\n",
    "def split_into_sentences(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the text into sentences.\n",
    "\n",
    "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead \n",
    "    to incorrect splitting because they are used as markers for splitting.\n",
    "\n",
    "    :param text: text to be split into sentences\n",
    "    :type text: str\n",
    "\n",
    "    :return: list of sentences\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    if \"No.\" in text: text = text.replace(\"No.\",\"No<prd>\")\n",
    "    if \"Jan.\" in text: text = text.replace(\"Jan.\",\"Jan<prd>\")\n",
    "    if \"Feb.\" in text: text = text.replace(\"Feb.\",\"Feb<prd>\")\n",
    "    if \"Mar.\" in text: text = text.replace(\"Mar.\",\"Mar<prd>\")\n",
    "    if \"Apr.\" in text: text = text.replace(\"Apr.\",\"Apr<prd>\")\n",
    "    if \"Jun.\" in text: text = text.replace(\"Jun.\",\"Jun<prd>\")\n",
    "    if \"Jul.\" in text: text = text.replace(\"Jul.\",\"Jul<prd>\")\n",
    "    if \"Aug.\" in text: text = text.replace(\"Aug.\",\"Aug<prd>\")\n",
    "    if \"Sep.\" in text: text = text.replace(\"Sep.\",\"Sep<prd>\")\n",
    "    if \"Sept.\" in text: text = text.replace(\"Sept.\",\"Sept<prd>\")\n",
    "    if \"Oct.\" in text: text = text.replace(\"Oct.\",\"Oct<prd>\")\n",
    "    if \"Nov.\" in text: text = text.replace(\"Nov.\",\"Nov<prd>\")\n",
    "    if \"Dec.\" in text: text = text.replace(\"Dec.\",\"Dec<prd>\")\n",
    "    if \"Corp.\" in text: text = text.replace(\"Corp.\",\"Corp<prd>\")\n",
    "    if \"Ltd.\" in text: text = text.replace(\"Ltd.\",\"Ltd<prd>\")\n",
    "    if \"vs.\" in text: text = text.replace(\"vs.\",\"vs<prd>\")\n",
    "    if \"e.g.\" in text: text = text.replace(\"e.g.\",\"e<prd>g<prd>\")\n",
    "    if \"i.e.\" in text: text = text.replace(\"i.e.\",\"i<prd>e<prd>\")\n",
    "    if \"Sen.\" in text: text = text.replace(\"Sen.\",\"Sen<prd>\")\n",
    "    if \"Calif.\" in text: text = text.replace(\"Calif.\",\"Calif<prd>\")\n",
    "    if \"Gov.\" in text: text = text.replace(\"Gov.\",\"Gov<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    text = text.replace('<ellipsis>', '...')\n",
    "    text = text.replace('<qst>', '?')\n",
    "    text = text.replace('<exc>', '!')\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
    "    return sentences\n",
    "\n",
    "def remove_parenthetical_sentences(sentences):\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Check if the entire sentence is within parentheses\n",
    "        if sentence.startswith('(') and sentence.endswith(')'):\n",
    "            continue  # Skip this sentence\n",
    "        cleaned_sentences.append(sentence)\n",
    "    return cleaned_sentences\n",
    "\n",
    "def merge_parenthetical_statements(text):\n",
    "    # Replace periods within parentheses with a placeholder\n",
    "    text = re.sub(r'\\(([^)]+)\\)', lambda m: \"(\" + m.group(1).replace('.', '<prd>') + \")\", text)\n",
    "    return text\n",
    "\n",
    "def replace_ellipses(text):\n",
    "    # Replace '...' with a placeholder\n",
    "    return re.sub(r'\\.\\.\\.', '<ellipsis>', text)\n",
    "\n",
    "def replace_sentence_stops_in_quotes(text):\n",
    "    # Define a function to replace sentence stops within a matched quote\n",
    "    def replace_stops(match):\n",
    "        # Replace all periods, question marks, and exclamation marks in the matched quote\n",
    "        temp = match.group(0).replace('.', '<prd>')\n",
    "        temp = temp.replace('?', '<qst>')\n",
    "        temp = temp.replace('!', '<exc>')\n",
    "        return temp\n",
    "    \n",
    "    # Regex-Muster, das Text in Anführungszeichen erfasst\n",
    "    quote_pattern = r'[\"“”](.*?)[\"“”]'\n",
    "    \n",
    "    # ersetzte alle Satzzeichen in Anführungszeichen\n",
    "    text = re.sub(quote_pattern, replace_stops, text, flags=re.UNICODE)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "for id, text in text:\n",
    "    split_text = split_into_sentences(merge_parenthetical_statements(replace_ellipses(replace_sentence_stops_in_quotes(text))))\n",
    "    cleaned_sentences = remove_parenthetical_sentences(split_text)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in cleaned_sentences:\n",
    "        sentence = remove_author_notes(sentence)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    # Jeden Satz in die Datenbank einfügen\n",
    "    for sequence, sentence in enumerate(sentences):\n",
    "        # Kürzer als 20 und länger als 1100 Zeichen überspringen\n",
    "        if len(sentence) < 20:\n",
    "            continue\n",
    "        if(len(sentence) > 1100):\n",
    "            continue\n",
    "        cursor.execute('''\n",
    "            INSERT INTO sentences (text_id, sentence_text, sequence)\n",
    "            VALUES (?, ?, ?)\n",
    "        ''', (id, sentence, sequence))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
