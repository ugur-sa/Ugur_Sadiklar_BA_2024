{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufteilen und Bereinigen des Volltexts in die einzelnen Sätze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import sqlite3\n",
    "\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|Prof|Capt|Cpt|Lt|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|edu|me)\"\n",
    "digits = \"([0-9])\"\n",
    "multiple_dots = r'\\.{2,}'\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect('sentiment.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create the sentence table if it doesn't exist\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS sentences (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        text_id INTEGER,\n",
    "        sentence_text TEXT,\n",
    "        sequence INTEGER,\n",
    "        finbert_result TEXT,\n",
    "        finbert_score REAL,\n",
    "        dffnsa_result TEXT,\n",
    "        dffnsa_score REAL,\n",
    "        fsa_result TEXT,\n",
    "        fsa_score REAL,\n",
    "        final_sentiment TEXT,\n",
    "        FOREIGN KEY (text_id) REFERENCES sentiment(id)\n",
    "    )\n",
    "''')\n",
    "\n",
    "cursor.execute('SELECT id, text FROM sentiment')\n",
    "text = cursor.fetchall()\n",
    "\n",
    "\n",
    "def remove_author_notes(text):\n",
    "    # Erweitern des Muster, um Updates oder andere Anmerkungen am Anfang zu erkennen\n",
    "    text = re.sub(r'^\\([^\\)]+\\)\\s*', '', text)\n",
    "\n",
    "    # Muster zum Abgleich von Autor und Ort\n",
    "    text = re.sub(r'By\\s.+?\\s\\(.+?\\)\\s*[-–]\\s*', '', text)\n",
    "\n",
    "    # Muster zum Erkennen von Monat und Tag (Datum)\n",
    "    text = re.sub(r'\\w{3}\\s\\d{1,2}\\s\\([^)]*\\)\\s*-\\s*', '', text)\n",
    "\n",
    "    # Muster zur Erkennung von zusätzlichen Hinweisen am Ende\n",
    "    text = re.sub(r'\\(Reporting by [\\w\\s,]+;\\s*additional reporting by [\\w\\s,]+;\\s*Editing by [\\w\\s,]+\\)$', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "    return text\n",
    "\n",
    "# https://stackoverflow.com/a/31505798 (source)\n",
    "def split_into_sentences(text: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Split the text into sentences.\n",
    "\n",
    "    If the text contains substrings \"<prd>\" or \"<stop>\", they would lead \n",
    "    to incorrect splitting because they are used as markers for splitting.\n",
    "\n",
    "    :param text: text to be split into sentences\n",
    "    :type text: str\n",
    "\n",
    "    :return: list of sentences\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    text = re.sub(multiple_dots, lambda match: \"<prd>\" * len(match.group(0)) + \"<stop>\", text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    if \"No.\" in text: text = text.replace(\"No.\",\"No<prd>\")\n",
    "    if \"Jan.\" in text: text = text.replace(\"Jan.\",\"Jan<prd>\")\n",
    "    if \"Feb.\" in text: text = text.replace(\"Feb.\",\"Feb<prd>\")\n",
    "    if \"Mar.\" in text: text = text.replace(\"Mar.\",\"Mar<prd>\")\n",
    "    if \"Apr.\" in text: text = text.replace(\"Apr.\",\"Apr<prd>\")\n",
    "    if \"Jun.\" in text: text = text.replace(\"Jun.\",\"Jun<prd>\")\n",
    "    if \"Jul.\" in text: text = text.replace(\"Jul.\",\"Jul<prd>\")\n",
    "    if \"Aug.\" in text: text = text.replace(\"Aug.\",\"Aug<prd>\")\n",
    "    if \"Sep.\" in text: text = text.replace(\"Sep.\",\"Sep<prd>\")\n",
    "    if \"Sept.\" in text: text = text.replace(\"Sept.\",\"Sept<prd>\")\n",
    "    if \"Oct.\" in text: text = text.replace(\"Oct.\",\"Oct<prd>\")\n",
    "    if \"Nov.\" in text: text = text.replace(\"Nov.\",\"Nov<prd>\")\n",
    "    if \"Dec.\" in text: text = text.replace(\"Dec.\",\"Dec<prd>\")\n",
    "    if \"Corp.\" in text: text = text.replace(\"Corp.\",\"Corp<prd>\")\n",
    "    if \"Ltd.\" in text: text = text.replace(\"Ltd.\",\"Ltd<prd>\")\n",
    "    if \"vs.\" in text: text = text.replace(\"vs.\",\"vs<prd>\")\n",
    "    if \"e.g.\" in text: text = text.replace(\"e.g.\",\"e<prd>g<prd>\")\n",
    "    if \"i.e.\" in text: text = text.replace(\"i.e.\",\"i<prd>e<prd>\")\n",
    "    if \"Sen.\" in text: text = text.replace(\"Sen.\",\"Sen<prd>\")\n",
    "    if \"Calif.\" in text: text = text.replace(\"Calif.\",\"Calif<prd>\")\n",
    "    if \"Gov.\" in text: text = text.replace(\"Gov.\",\"Gov<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    text = text.replace('<ellipsis>', '...')\n",
    "    text = text.replace('<qst>', '?')\n",
    "    text = text.replace('<exc>', '!')\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    if sentences and not sentences[-1]: sentences = sentences[:-1]\n",
    "    return sentences\n",
    "\n",
    "def remove_parenthetical_sentences(sentences):\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # Überprüfen, ob der gesamte Satz in Klammern steht\n",
    "        if sentence.startswith('(') and sentence.endswith(')'):\n",
    "            continue  # Überspringen\n",
    "        cleaned_sentences.append(sentence)\n",
    "    return cleaned_sentences\n",
    "\n",
    "def merge_parenthetical_statements(text):\n",
    "    # Ersetzte Punkte innerhalb von Klammern durch einen Platzhalter\n",
    "    text = re.sub(r'\\(([^)]+)\\)', lambda m: \"(\" + m.group(1).replace('.', '<prd>') + \")\", text)\n",
    "    return text\n",
    "\n",
    "def replace_ellipses(text):\n",
    "    # Ersetzte '...' durch einen Platzhalter\n",
    "    return re.sub(r'\\.\\.\\.', '<ellipsis>', text)\n",
    "\n",
    "def replace_sentence_stops_in_quotes(text):\n",
    "    # Definiere eine Funktion, um Satzzeichen innerhalb eines zitierten Textes zu ersetzen\n",
    "    def replace_stops(match):\n",
    "        # Ersetze alle Punkte, Fragezeichen und Ausrufezeichen im zitierten Text\n",
    "        temp = match.group(0).replace('.', '<prd>')\n",
    "        temp = temp.replace('?', '<qst>')\n",
    "        temp = temp.replace('!', '<exc>')\n",
    "        return temp\n",
    "    \n",
    "    # Regex-Muster, das Text in Anführungszeichen erfasst\n",
    "    quote_pattern = r'[\"“”](.*?)[\"“”]'\n",
    "    \n",
    "    # ersetzte alle Satzzeichen in Anführungszeichen\n",
    "    text = re.sub(quote_pattern, replace_stops, text, flags=re.UNICODE)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "for id, text in text:\n",
    "    split_text = split_into_sentences(merge_parenthetical_statements(replace_ellipses(replace_sentence_stops_in_quotes(text))))\n",
    "    cleaned_sentences = remove_parenthetical_sentences(split_text)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    for sentence in cleaned_sentences:\n",
    "        sentence = remove_author_notes(sentence)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    # Jeden Satz in die Datenbank einfügen\n",
    "    for sequence, sentence in enumerate(sentences):\n",
    "        # Kürzer als 20 und länger als 1100 Zeichen überspringen\n",
    "        if len(sentence) < 20:\n",
    "            continue\n",
    "        if(len(sentence) > 1100):\n",
    "            continue\n",
    "        cursor.execute('''\n",
    "            INSERT INTO sentences (text_id, sentence_text, sequence)\n",
    "            VALUES (?, ?, ?)\n",
    "        ''', (id, sentence, sequence))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
